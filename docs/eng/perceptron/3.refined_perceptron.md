# Improving upon the simple perceptron

As we progressed forward in this examples, we came to realize that in particular, this was a trivial one, and not very useful. What we want to do now is to solve some of its problems, and mainly expand the prediction capabilities, such as it not only guesses _f(x) = x_ but also _f(x) = mx + b_

## Current issues

- The perceptron can't deal with all of its inputs being 0, if we go back to our first calculation definition we have: _x<sub>0</sub> * w<sub>0</sub> + x<sub>1</sub> * w<sub>1</sub> + ... +  x<sub>n</sub> * w<sub>n</sub>_ . Here we already can spot the problem, if in _x<sub>0</sub> to x<sub>n</sub>_ all _x_ values are 0 then the output will not be adjusted in spite of the weight change.

  - Solution: introduce a new input, called a _bias_ that in this case is always going to be _1_ then even if all inputs are _&varnothing;_ we can still adjust the bias weight to get a meaningful result. Now  we have: _x<sub>0</sub> * w<sub>0</sub> + x<sub>1</sub> * w<sub>1</sub> + ... +  x<sub>n</sub> * w<sub>n</sub> + **b<sub>1</sub>*w<sub>b<sub>1</sub></sub>**_ where _b<sub>1</sub> = 1_

- The perceptron can only classify points above or below _f(x) = x_, we want to generalize it to _f(x) = mx + b_
