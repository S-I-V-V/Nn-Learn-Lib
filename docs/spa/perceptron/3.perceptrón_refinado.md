# Mejorando nuestro primer perceptrón

Mientras progresamos con estos ejemplos, nos damos cuenta que este en particular es uno trivial, de hecho, no muy útil. Lo que realmente queremos saber ahora, es como resolver algunos de sus problemas y principalmente expandir su alcance de predicción, de manera que ahora no solo pueda clasificar puntos para _f(x) = x_ si no para cualquier recta _f(x) = mx +b_

## Problemas conocidos

- Nuestro perceptrón no puede trabajar con todas sus entradas siendo 0, si es que nos referimos a nuestra formula previa, sabemos que: _x<sub>0</sub> * w<sub>0</sub> + x<sub>1</sub> * w<sub>1</sub> + ... +  x<sub>n</sub> * w<sub>n</sub>_ . Y aquí podemos ver el problema claramente, si en _x<sub>0</sub> + ... + x<sub>n</sub>_ todos los valores _x_ son 0, entonces la salida no será ajustada bajo ningún cambio de peso.

  - Solución: Introducir una nueva variable llamada _bias_ que en este caso siempre será _1_, de esta manera incluso si todas las entradas son _&varnothing;_ podemos seguir ajustando el peso de la variable _bias_ para obtener un resultado significativo. Ahora tenemos: _x<sub>0</sub> * w<sub>0</sub> + x<sub>1</sub> * w<sub>1</sub> + ... +  x<sub>n</sub> * w<sub>n</sub> + **b<sub>1</sub>*w<sub>b<sub>1</sub></sub>**_ donde _b<sub>1</sub> = 1_

  - El perceptrón solo puede clasificar puntos encima o debajo de la recta _f(x) = x_ y queremos generalizarlo a _f(x) = mx + b_
